### For details see: https://github.com/openai/codex/blob/main/docs/config.md

model_provider = "watsonx"
profile = "gptoss"

##
## General permission configurations
##

sandbox_mode = "danger-full-access"
approval_policy = "never"
tools.web_search = true

##
## Project/folder permissions
##

# Trust the folder we will be working in during this lab
[projects."/home/project/eifkl-Expense-Tracking-Demo---Codex"]
trust_level = "trusted"

##
## OpenAI providers
##

[model_providers.sn-openai]
name = "OpenAI"
base_url = "https://api.openai.com/v1"
env_key = "OPENAI_API_KEY"
http_headers = { "SN-Event" = "techxchange2025" }
wire_api = "responses"

[profiles.gpt-5]
model = "gpt-5"
model_provider = "sn-openai"
model_reasoning_effort = "low"

[profiles.gpt-5-mini]
model = "gpt-5-mini"
model_provider = "sn-openai"

[profiles.gpt-5-nano]
model = "gpt-5-nano"
model_provider = "sn-openai"

##
## watsonx providers
##

[model_providers.watsonx]
name = "watsonx"
base_url = "http://0.0.0.0:4000"
http_headers = { "SN-Event" = "techxchange2025" }

[profiles.llama4]
model = "watsonx/meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
model_provider = "watsonx"

[profiles.granite3]
model = "watsonx/ibm/granite-3-3-8b-instruct"
model_provider = "watsonx"

[profiles.granite4]
model = "watsonx/ibm/granite-4-h-small"
model_provider = "watsonx"

[profiles.gptoss]
model = "watsonx/openai/gpt-oss-120b"
model_provider = "watsonx"
